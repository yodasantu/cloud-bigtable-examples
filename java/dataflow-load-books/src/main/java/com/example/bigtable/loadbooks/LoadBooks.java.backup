/*
 * Copyright (C) 2016 Google Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License"); you may not
 * use this file except in compliance with the License. You may obtain a copy of
 * the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
 * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
 * License for the specific language governing permissions and limitations under
 * the License.
 */

package com.example.bigtable.loadbooks;

import com.google.cloud.bigtable.dataflow.CloudBigtableIO;
import com.google.cloud.bigtable.dataflow.CloudBigtableOptions;
import com.google.cloud.bigtable.dataflow.CloudBigtableTableConfiguration;
import com.google.cloud.dataflow.sdk.Pipeline;
import com.google.cloud.dataflow.sdk.io.TextIO;
import com.google.cloud.dataflow.sdk.options.PipelineOptionsFactory;
import com.google.cloud.dataflow.sdk.transforms.Filter;
import com.google.cloud.dataflow.sdk.transforms.FlatMapElements;
import com.google.cloud.dataflow.sdk.transforms.MapElements;
import com.google.cloud.dataflow.sdk.values.TypeDescriptor;
import java.nio.ByteBuffer;
import java.nio.charset.Charset;
import java.nio.charset.StandardCharsets;
import java.util.Arrays;
import org.apache.hadoop.hbase.client.Mutation;
import org.apache.hadoop.hbase.client.Put;
import org.apache.hadoop.hbase.util.Bytes;

/**
 * A sample to load the Google Books Syntactic N-grams from Cloud Storage into Bigtable.
 *
 * <p>See http://commondatastorage.googleapis.com/books/syntactic-ngrams/index.html
 * for more information about the syntactic n-grams datasets.
 */
public class LoadBooks {
  private static final Charset STRING_ENCODING = StandardCharsets.UTF_8;
  private static final byte[] FAMILY = Bytes.toBytes("cf1");
  private static final byte[] COUNT_QUALIFIER = Bytes.toBytes("count");

  public static interface BigtableCsvOptions extends CloudBigtableOptions {
    String getColumnSeparator();

    void setColumnSeparator(String separator);

    String getInputFile();

    void setInputFile(String location);
  }

  public static void main(String[] args) {
    // CloudBigtableOptions is one way to retrieve the options.  It's not required.
    // https://github.com/GoogleCloudPlatform/cloud-bigtable-examples/blob/master/java/dataflow-connector-examples/src/main/java/com/google/cloud/bigtable/dataflow/example/HelloWorldWrite.java
    BigtableCsvOptions options =
        PipelineOptionsFactory.fromArgs(args).withValidation().as(BigtableCsvOptions.class);
    CloudBigtableTableConfiguration config =
        CloudBigtableTableConfiguration.fromCBTOptions(options);

    final String columnSeparator;
    if (options.getColumnSeparator() == null) {
      columnSeparator = "\t"; // ","
    } else {
      columnSeparator = options.getColumnSeparator();
    }

    Pipeline p = Pipeline.create(options);

    CloudBigtableIO.initializeForWrite(p);

    p.apply(TextIO.Read.from(options.getInputFile()))
        .apply(
            FlatMapElements.via((String doc) -> Arrays.asList(doc.split("\n")))
                .withOutputType(new TypeDescriptor<String>() {}))
        .apply(Filter.byPredicate((String line) -> !line.isEmpty()))

        .apply(
            MapElements.via(
                    (String line) -> {
                      String[] elements = line.split(columnSeparator);
                      byte[] key = elements[1].getBytes(STRING_ENCODING);
                      int count = Integer.parseInt(elements[2]);

                      // The byte order of a newly-created byte buffer is
                      // always big endian (network byte order).
                      // http://docs.oracle.com/javase/6/docs/api/java/nio/ByteBuffer.html#order()
                      byte[] data = ByteBuffer.allocate(Integer.BYTES).putInt(count).array();
                      return (Mutation) new Put(key).addColumn(FAMILY, COUNT_QUALIFIER, data);
                    })
                .withOutputType(new TypeDescriptor<Mutation>() {}))

        .apply(CloudBigtableIO.writeToTable(config));

    // Run the pipeline.
    p.run();
  }
}
